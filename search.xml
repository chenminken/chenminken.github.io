<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Machine Learning Week1 Note</title>
    <url>/2019/09/13/Machine-Learning-Week1-Note/</url>
    <content><![CDATA[<p>此系列博文是学习Coursera上Stanford的《Machine Learning》MOOC的笔记。</p>
<p>课程共分为11周，大约需要56小时学习。</p>
<p>此文是第一周的笔记。</p>
<h2 id="学习动机"><a href="#学习动机" class="headerlink" title="学习动机"></a>学习动机</h2><p>本课程是在同学的推荐下学习的，因为大四的两个项目都需要用到机器学习的知识和工具，所以需要先对机器学习有一个大概的了解。这门课程是很有名的。且Coursera上的评分为4.9，有250多万人注册过这门课！</p>
<p>Ng的课程说明中对本门课程的定义为不仅</p>
<h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>机器学习的应用有：</p>
<ol>
<li>垃圾邮件拦截。</li>
<li>网页搜索。</li>
<li>电子相册的面孔识别</li>
</ol>
<p>机器学习适用的场景：代码不能手动编写出来。比如：</p>
<ol>
<li>直升机自动驾驶</li>
<li>自然语言识别</li>
<li>视觉识别</li>
</ol>
<p>机器学习在数据挖掘中的应用。</p>
<p>推荐系统，点击流。</p>
<h2 id="什么是机器学习？"><a href="#什么是机器学习？" class="headerlink" title="什么是机器学习？"></a>什么是机器学习？</h2><p>公认的机器学习的定义有两种说法。一种是Mitchell提出的ETP定义，一种是</p>
<p>Arthur Samuel提出的学科定义。</p>
<h3 id="ETP（Experience-Task-Performance）"><a href="#ETP（Experience-Task-Performance）" class="headerlink" title="ETP（Experience, Task, Performance）"></a>ETP（Experience, Task, Performance）</h3><blockquote>
<p>A computer is said to learn from experience E with respect to some class of tasks T and performance measure P, if its performance at tasks in T, as measured by P, improves with experience E.</p>
</blockquote>
<p>Experience，实验经历。</p>
<p>Task：任务。</p>
<p>Performance：预测的准确度。</p>
<h3 id="Samuel的学科定义"><a href="#Samuel的学科定义" class="headerlink" title="Samuel的学科定义"></a>Samuel的学科定义</h3><blockquote>
<p>Machine Learning is the field of study gives computers that ability to learn without being explicitly programmed.</p>
</blockquote>
<p>机器学习是研究赋予不用显性的编写代码就能使计算机获得学习的能力的学科。</p>
<h2 id="监督学习"><a href="#监督学习" class="headerlink" title="监督学习"></a>监督学习</h2><p>监督学习是指输入训练特征数据，并且告诉你正确的答案是什么，然后再输入未知的特征，通过对之前的数据挖掘出规律预测未知输入对应的输出。</p>
<p>监督学习需要使用标记好的特征数据训练。</p>
<p>监督学习可分为两种形式。一种是分类（Classification），分类的结果是离散有限的。另外一种是回归（regression），回归的输出结果是连续的。以卖房为例，分类的结果可以是预测指定房子在未来三个月是否能卖出去。而回归的结果可以是符合指定条件（比如面积和地段）的房子的预期价格。价格既可以是10000，也可以是10001.23。</p>
<p>在上面的例子中，面积和地段是学习模型的两个特征，除了它们以外，可能的特征还有小区绿化率、1公里内的地铁站的数量等等特征。如果需要，甚至可以使用近乎无穷数量的特征进行监督学习。</p>
<h2 id="非监督学习"><a href="#非监督学习" class="headerlink" title="非监督学习"></a>非监督学习</h2><p>非监督学习不需要知道输入数据的标签和分类，而是通过输入数据的结构聚类（Clustering）。比如google新闻推荐，自动以一个新闻事件为主题，聚集相关的新闻报道。或者社交网络中人群分类都可以使用非监督学习进行。</p>
<p>课程中举了一个Cokcktail Party Problem的问题。即通过两个不同位置的声源分离出环境音和人声。</p>
<p><strong>TODO：实现一个算法</strong></p>
]]></content>
      <tags>
        <tag>MachineLearning</tag>
        <tag>Coursera</tag>
      </tags>
  </entry>
  <entry>
    <title>如何测试那些难以测试的方法？(stdin/stdout标准输入输出，文件，main方法，private私有方法)</title>
    <url>/2019/09/23/%E5%A6%82%E4%BD%95%E6%B5%8B%E8%AF%95%E9%82%A3%E4%BA%9B%E9%9A%BE%E4%BB%A5%E6%B5%8B%E8%AF%95%E7%9A%84%E6%96%B9%E6%B3%95/</url>
    <content><![CDATA[<h2 id="如何测试标准输出中的内容"><a href="#如何测试标准输出中的内容" class="headerlink" title="如何测试标准输出中的内容"></a>如何测试标准输出中的内容</h2><p>标准输出：<code>System.out.println()</code></p>
<p>方法流程：</p>
<ol>
<li>使用<code>OutputStream, System.setOut</code>重定向输出流</li>
<li>使用<code>System.getProperty(&quot;line.separator)</code>来正确的测试下一行</li>
<li>使用<code>System.setOut, System.out</code>恢复输出流</li>
</ol>
<hr>
<h3 id="样例代码"><a href="#样例代码" class="headerlink" title="样例代码"></a>样例代码</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// PrintClass.java</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">PrintClass</span> </span>&#123;</span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">printSome</span><span class="params">()</span> </span>&#123;</span><br><span class="line">		System.out.println(<span class="string">"Just follow your heard"</span>);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// PrintClassTest.java,忽略掉import的部分</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">PrintClassTest</span> </span>&#123;</span><br><span class="line">	<span class="meta">@Test</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">testPrintSome</span><span class="params">()</span> </span>&#123;</span><br><span class="line">		<span class="comment">// 重定向标准输出到指定printstream中</span></span><br><span class="line">		OutputStream os = <span class="keyword">new</span> ByteArrayOutputStream();</span><br><span class="line">		PrintStream ps = <span class="keyword">new</span> PrintStream(os);</span><br><span class="line">		System.setOut(ps);</span><br><span class="line">		<span class="comment">// 执行测试代码</span></span><br><span class="line">		PrintClass pc = <span class="keyword">new</span> PrintClass();</span><br><span class="line">		pc.printSome();</span><br><span class="line">		assertEquals(<span class="string">"Just follow your heard"</span></span><br><span class="line">						+ System.getProperty(<span class="string">"line.separator"</span>),</span><br><span class="line">                os.toString());</span><br><span class="line">		<span class="comment">// 恢复重定向</span></span><br><span class="line">		PrintStream originalOut = System.out;</span><br><span class="line">    	System.setOut(originalOut);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>完整代码在：<a href="https://github.com/chenminken/software-testing/tree/master/week2/printtest" target="_blank" rel="noopener">week2:printtest</a></p>
<h2 id="如何测试私有方法"><a href="#如何测试私有方法" class="headerlink" title="如何测试私有方法"></a>如何测试私有方法</h2><p>Java中的私有方法不能通过obj.method()的方式来调用。如果需要测试私有方法怎么办？</p>
<p>使用反射机制获取这个私有方法。</p>
<p>需要使用到的方法<code>Class.getDeclaredMethod(), Method.setAccessible(), Method.invoke()</code></p>
<p>方法流程：</p>
<ol>
<li>获取需要测试类的class对象（可以使用class.forname的方法，也可以直接使用[ClassName].class的方法）</li>
<li>获取该class对象指定的私有方法的Method对象（<code>[classobj.class].getDeclaredMethod(String name, Class&lt;?&gt;... parameterTypes)</code>）</li>
<li>修改私有方法的访问性为公开访问(<code>[MethodObj].setAccessible(true)</code>。</li>
<li>实例化需要测试类的object对象(<code>[ClassName.class].newInstance()</code>)</li>
<li>调用该私有方法测试(<code>[MethodObj].invoke([objectInstance], ...)</code>)</li>
</ol>
<hr>
<h3 id="样例代码-1"><a href="#样例代码-1" class="headerlink" title="样例代码"></a>样例代码</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// PrivateMethodClass.java</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">PrivateMethodClass</span> </span>&#123;</span><br><span class="line">	<span class="function"><span class="keyword">private</span> <span class="keyword">int</span> <span class="title">privatePlus</span><span class="params">(<span class="keyword">int</span> a, <span class="keyword">int</span> b)</span> </span>&#123;</span><br><span class="line">		<span class="keyword">return</span> a + b;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// PrivateMethodClassTest.java</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">PrivateMethodClassTest</span> </span>&#123;</span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">testPrivatePlus1</span><span class="params">()</span> <span class="keyword">throws</span> NoSuchMethodException, ClassNotFoundException, IllegalAccessException, InstantiationException, InvocationTargetException </span>&#123;</span><br><span class="line">        Class cls = Class.forName(<span class="string">"PrivateMethodClass"</span>);</span><br><span class="line">        Method msd = cls.getDeclaredMethod(<span class="string">"privatePlus"</span>, <span class="keyword">int</span>.class, <span class="keyword">int</span>.class);</span><br><span class="line">        msd.setAccessible(<span class="keyword">true</span>);</span><br><span class="line">        Object obj = cls.newInstance();</span><br><span class="line">        <span class="keyword">int</span> res = (Integer)msd.invoke(obj, <span class="number">4</span>,<span class="number">6</span>);</span><br><span class="line">        assertEquals(<span class="number">10</span>, res);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>完整代码在：<a href="https://github.com/chenminken/software-testing/tree/master/week2/privateTest" target="_blank" rel="noopener">week2:privateTest</a></p>
]]></content>
      <tags>
        <tag>软件测试</tag>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>python程序同步webdav网盘（坚果云、owncloud)</title>
    <url>/2020/01/10/python%E7%A8%8B%E5%BA%8F%E5%90%8C%E6%AD%A5webdav%E7%BD%91%E7%9B%98%EF%BC%88%E5%9D%9A%E6%9E%9C%E4%BA%91%E3%80%81owncloud%EF%BC%89/</url>
    <content><![CDATA[<p>在编写一个Django项目的时候有定时备份数据文件的需求。因为项目运行在云服务器中，担心的是服务器挂掉，所以备份的地方不能是同一台服务器。在这个项目里自己去建一个服务器来管理备份数据显得没有必要。目前网络存储提供商有许多家，我选取的方案是编写python定时程序连接支持WebDAV协议的网盘，例如坚果云和owncloud。</p>
<p>分为两部分：</p>
<ol>
<li>Python同步代码编写</li>
<li>Django定时任务编写</li>
</ol>
<h2 id="Python同步代码编写"><a href="#Python同步代码编写" class="headerlink" title="Python同步代码编写"></a>Python同步代码编写</h2><p>使用<a href="https://pypi.org/project/webdavclient3/" target="_blank" rel="noopener">webdavclient3</a>库来处理webDAV协议的部分。先安装：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">pip install webdavclient3</span><br></pre></td></tr></table></figure>

<p>然后在自己的项目的某个地方建立一个py文件。我选的是<code>[项目目录]\utils\backup\backup.py</code></p>
<p>编写python代码：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> webdav3.client <span class="keyword">import</span> Client</span><br><span class="line"><span class="keyword">from</span> datetime <span class="keyword">import</span> datetime</span><br><span class="line"><span class="keyword">from</span> webdav3.exceptions <span class="keyword">import</span> LocalResourceNotFound</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="comment"># invoke this function every day.</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">upload</span><span class="params">()</span>:</span></span><br><span class="line">    options = &#123;</span><br><span class="line">        <span class="string">'webdav_hostname'</span>: <span class="string">"网盘地址，如果是坚果云，不能只输入/dav/路径，似乎这个文件夹不能访问，在下面再建一个文件夹，比如backup。网址中需要有backup的地址比如https://dav.jianguoyun.com/dav/backup"</span>,</span><br><span class="line">        <span class="string">'webdav_login'</span>: <span class="string">"用户名"</span>,</span><br><span class="line">        <span class="string">'webdav_password'</span>: <span class="string">"密码，如果是坚果云填写应用密码"</span>,</span><br><span class="line">        <span class="string">'disable_check'</span>: <span class="literal">True</span>, <span class="comment">#有的网盘不支持check功能</span></span><br><span class="line">    &#125;</span><br><span class="line">    client = Client(options)</span><br><span class="line">		<span class="comment"># 我选择用时间戳为备份文件命名</span></span><br><span class="line">    file_name = str(math.floor(datetime.now().timestamp())) + <span class="string">'.bak'</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="comment"># 写死的路径，第一个参数是网盘地址</span></span><br><span class="line">        client.upload(<span class="string">'backup/'</span> + file_name, <span class="string">'本地地址，绝对路径'</span>)</span><br><span class="line">        <span class="comment"># 打印结果，之后会重定向到log</span></span><br><span class="line">        print(<span class="string">'upload at '</span> + file_name)</span><br><span class="line">    <span class="keyword">except</span> LocalResourceNotFound <span class="keyword">as</span> exception:</span><br><span class="line">        print(<span class="string">'An error happen: LocalResourceNotFound ---'</span>  + file_name)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 如果是直接调用文件，执行upload()</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    print(<span class="string">'run upload'</span>)</span><br><span class="line">    upload()</span><br></pre></td></tr></table></figure>

<p>Python的代码相对简短。只需要在服务器的命令行执行<code>python upload.py</code>，备份文件自动上传到网盘。然而还不完整，这个程序的目的是定期执行。接下来结合Django的定期执行接口做到每日备份。</p>
<h2 id="Django定时任务编写"><a href="#Django定时任务编写" class="headerlink" title="Django定时任务编写"></a>Django定时任务编写</h2><p>Django是目前很流行的python web服务框架。通过django自带的命令创建project和app（这一部分不讲）。</p>
<p>当项目建好后，使用<code>python manage.py</code>可以运行项目、数据库代码整合。开发者可以通过继承BaseCommand类来自定义命令，然后再通过django_crontab定期执行命令。或者不通过自定义命令，直接使用django_crontab定期执行函数。</p>
<h3 id="创建backupCmd命令"><a href="#创建backupCmd命令" class="headerlink" title="创建backupCmd命令"></a>创建backupCmd命令</h3><p>在之前创建的app下新建management/commands目录，在该目录下新建<code>backupCmd.py</code></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">from django.core.management.base import BaseCommand</span><br><span class="line">from utils.backup.backup import upload</span><br><span class="line"></span><br><span class="line">class Command(BaseCommand):</span><br><span class="line">    def handle(self, *args, **options):</span><br><span class="line">        upload()</span><br></pre></td></tr></table></figure>

<p>当完成后，在项目根目录下执行<code>python manage.py backupCmd</code>就可以单次执行程序了。</p>
<p>在setting.py尾部添加:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 运行定时函数，每天1点运行。</span><br><span class="line">CRONJOBS = [</span><br><span class="line">    (&apos;0 01 * * *&apos;, &apos;utils.backup.backup&apos;,&apos;&gt;&gt; ~/test_crontab.log&apos;)</span><br><span class="line">]</span><br></pre></td></tr></table></figure>

<p>或</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 运行定时命令， </span><br><span class="line">CRONJOBS = [</span><br><span class="line">    (&apos;*/1 * * * *&apos;, &apos;django.core.management.call_command&apos;, [&apos;backupCmd&apos;], &#123;&#125;, &apos;&gt;&gt; ~/test_crontab.log&apos;),</span><br><span class="line">]</span><br></pre></td></tr></table></figure>

<p>然后执行<code>python manage.py crontab add</code>，定时任务加入其中。</p>
<p>当时间到达的时候，程序将自动运行。日志会输出到<code>~/test_crontab.log</code>中。</p>
<p>linux中的定时任务crontab的语法如下:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">*  *  *  *  * command</span><br><span class="line">分钟(0-59) 小时(0-23) 每个月的哪一天(1-31) 月份(1-12) 周几(0-6) shell脚本或者命令</span><br></pre></td></tr></table></figure>

<p>对于使用到的网盘，希望能够付费支持一下。</p>
]]></content>
  </entry>
  <entry>
    <title>用python写一个过滤器</title>
    <url>/2019/09/27/%E7%94%A8python%E5%86%99%E4%B8%80%E4%B8%AA%E8%BF%87%E6%BB%A4%E5%99%A8/</url>
    <content><![CDATA[<p>计算机视觉课Assigment2的内容.</p>
<p>要求写出一个图像的过滤器出来。</p>
<h2 id="要求"><a href="#要求" class="headerlink" title="要求"></a>要求</h2><p><strong>Image Filtering.</strong>Image filtering (or convolution) is a fundamental image processing tool. You will be writing your own function to implement image filtering from scratch. More specifically, you will implement my_imfilter()which imitates the filter2Dfunction in the OpenCV library. As specified in student_code.py, your filtering algorithm must</p>
<p>(1) support grayscale and color images</p>
<p>(2) support arbitrary shaped filters, as long as both dimensions are odd</p>
<p>(e.g. 7x9 filters but not 4x5 filters)</p>
<p>(3) pad the input image with zeros or reflected image content</p>
<p>(4) return a filtered image which is the same resolution as the input image.</p>
<p>使用numpy，PIL。</p>
<h2 id="步骤："><a href="#步骤：" class="headerlink" title="步骤："></a>步骤：</h2><ol>
<li>导入图像（不属于本次任务）</li>
<li>生成过滤核（不属于本次任务）</li>
<li>padding</li>
<li>calculate</li>
<li>normalization（不属于本次任务，即假设过滤核和图像已经做好了正则化）</li>
<li>截断</li>
</ol>
<hr>
<h2 id="函数定义"><a href="#函数定义" class="headerlink" title="函数定义"></a>函数定义</h2><p>图像过滤器的核心是一个function，函数的定义</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">my_imfilter</span><span class="params">(image, filter)</span></span></span><br><span class="line"><span class="function">	<span class="title">return</span> <span class="title">filtered_image</span></span></span><br></pre></td></tr></table></figure>

<h2 id="设计思路"><a href="#设计思路" class="headerlink" title="设计思路"></a>设计思路</h2><p>输入的图像为image，image可以为黑白或者RGB彩色。（channel=1 or channel=3)</p>
<p>所以输入的image.ndim可能为2或者为3.</p>
<p>第一部分代码需要判断黑白和彩色的情况.</p>
<p>图片过滤器会将原图片的尺寸缩小,因为进行卷积操作是将原图像的一个矩阵框中的点和过滤核相乘后在求和得到新图像的一个点的值。</p>
<p>【公式和图像】</p>
<p>假设原始图像的高和宽为img_h, img_w，过滤核的大小为filter_h, filter_w。这里有一个条件过滤核的长宽都必须为为奇数。（为什么呢？）那么除掉最中心的像素外，过滤核可以被分为四等份。每一部分的长宽(padding)为 pad_h = (filter_h-1)/2和pad_w = (filter_w-1)/2</p>
<p>那么输出的尺寸为img_h - pad_h * 2 和 img_w - pad_w *2，因为图像两边都需要减去pad_h的尺寸。</p>
<p>同时我们还要给过滤器做一个上下左右变换。因为卷积操作和相关操作的过滤核移动方向是相反的，应该是从下往上，从右往左。</p>
<h2 id="实例代码："><a href="#实例代码：" class="headerlink" title="实例代码："></a>实例代码：</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">my_imfilter</span><span class="params">(image, filter)</span>:</span></span><br><span class="line">  <span class="string">"""</span></span><br><span class="line"><span class="string">  Apply a filter to an image. Return the filtered image.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  Args</span></span><br><span class="line"><span class="string">  - image: numpy nd-array of dim (m, n, c)</span></span><br><span class="line"><span class="string">  - filter: numpy nd-array of dim (k, k)</span></span><br><span class="line"><span class="string">  Returns</span></span><br><span class="line"><span class="string">  - filtered_image: numpy nd-array of dim (m, n, c)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  HINTS:</span></span><br><span class="line"><span class="string">  - You may not use any libraries that do the work for you. Using numpy to work</span></span><br><span class="line"><span class="string">   with matrices is fine and encouraged. Using opencv or similar to do the</span></span><br><span class="line"><span class="string">   filtering for you is not allowed.</span></span><br><span class="line"><span class="string">  - I encourage you to try implementing this naively first, just be aware that</span></span><br><span class="line"><span class="string">   it may take an absurdly long time to run. You will need to get a function</span></span><br><span class="line"><span class="string">   that takes a reasonable amount of time to run so that the TAs can verify</span></span><br><span class="line"><span class="string">   your code works.</span></span><br><span class="line"><span class="string">  - Remember these are RGB images, accounting for the final image dimension.</span></span><br><span class="line"><span class="string">  """</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">assert</span> filter.shape[<span class="number">0</span>] % <span class="number">2</span> == <span class="number">1</span></span><br><span class="line">  <span class="keyword">assert</span> filter.shape[<span class="number">1</span>] % <span class="number">2</span> == <span class="number">1</span></span><br><span class="line">  <span class="comment"># 默认设置图像的通道数，如果只有一个通道，即输入图片是二维的。</span></span><br><span class="line">  channel = <span class="number">1</span></span><br><span class="line">  <span class="comment"># 如果输入维度=3，通道数等于第三个维度的元素数量</span></span><br><span class="line">  <span class="keyword">if</span> image.ndim == <span class="number">3</span>:</span><br><span class="line">    channel = image.shape[<span class="number">2</span>]</span><br><span class="line">  <span class="comment"># 获取图片的长度和宽度</span></span><br><span class="line">  image_h, image_w = image.shape[:<span class="number">2</span>]</span><br><span class="line">  <span class="comment"># 将过滤核做上下、左右翻转，以确保是卷积操作而不是相关操作</span></span><br><span class="line">  filter = np.flipud(filter)</span><br><span class="line">  filter = np.fliplr(filter)</span><br><span class="line">  <span class="comment"># 获取过滤核的长度和宽度</span></span><br><span class="line">  filter_h, filter_w = filter.shape</span><br><span class="line">  pad_h = (filter_h - <span class="number">1</span>) // <span class="number">2</span></span><br><span class="line">  pad_w = (filter_w - <span class="number">1</span>) // <span class="number">2</span></span><br><span class="line">  <span class="comment"># 先扩充原图像,为了不影响原图像，需要复制一份图像</span></span><br><span class="line">  image_cp = image.copy()</span><br><span class="line">  image_cp = np.pad(image_cp,[(pad_h,pad_h),(pad_w,pad_w),(<span class="number">0</span>,<span class="number">0</span>)],<span class="string">"constant"</span>)</span><br><span class="line">  <span class="comment"># 生成过滤后的图片的空容器，尺寸可以是原本的尺寸，在这里为了下面坐标转换方便，扩大了长宽。</span></span><br><span class="line">  filtered_image = np.zeros(image_cp.shape)</span><br><span class="line">  <span class="comment"># 第一层是对于不同的channel做卷积  </span></span><br><span class="line">  <span class="keyword">for</span> i <span class="keyword">in</span> range(channel):</span><br><span class="line">    <span class="comment"># 第二层是高度y轴像素遍历</span></span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range(pad_h,image_h+pad_h):</span><br><span class="line">        <span class="comment"># 第三层是宽度x轴像素遍历</span></span><br><span class="line">        <span class="keyword">for</span> k <span class="keyword">in</span> range(pad_w,image_w+pad_w):</span><br><span class="line">            <span class="comment"># 算法核心，加上上面的翻转式卷积操作，单独来看是相关操作。其实可以通过 step=-1来做</span></span><br><span class="line">            filtered_image[j,k,i] = np.sum(np.multiply(image_cp[j-pad_h:j+pad_h+<span class="number">1</span>,k-pad_w:k+pad_w+<span class="number">1</span>,i],filter))</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> filtered_image[pad_h:image_h+pad_h, pad_w:image_w+pad_w,:]</span><br></pre></td></tr></table></figure>

<hr>
<p>相关链接：</p>
<p><a href="https://zhuanlan.zhihu.com/p/33194385" target="_blank" rel="noopener">卷积与互相关的一点探讨</a></p>
]]></content>
  </entry>
  <entry>
    <title>软件测试week1 note</title>
    <url>/2019/09/09/%E8%BD%AF%E4%BB%B6%E6%B5%8B%E8%AF%95week1-note/</url>
    <content><![CDATA[]]></content>
  </entry>
  <entry>
    <title>用阿里云服务器自己搭建2do同步caldav服务器</title>
    <url>/2019/09/23/%E7%94%A8%E9%98%BF%E9%87%8C%E4%BA%91%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%87%AA%E5%B7%B1%E6%90%AD%E5%BB%BA2do%E5%90%8C%E6%AD%A5caldav%E6%9C%8D%E5%8A%A1%E5%99%A8/</url>
    <content><![CDATA[<h2 id="用阿里云服务器自己搭建2do同步caldav服务器"><a href="#用阿里云服务器自己搭建2do同步caldav服务器" class="headerlink" title="用阿里云服务器自己搭建2do同步caldav服务器"></a>用阿里云服务器自己搭建2do同步caldav服务器</h2><p>一个月前，把任务管理从Microsoft TO-DO迁移到2Do中，自己手上常用一台小米9和Macbook Pro，同步成了问题，不能使用icloud remainder。那就只有DropBox等服务可用。<br>因为Dropbox在国内不稳定的连接以及近阶段自己手上的梯子挂掉了，所以琢磨自己搭一个同步使用的服务器。<br>流程非常简单。一个小时以内就可办完。<br>使用到的:</p>
<ol>
<li>阿里云ECS低配版，如果使用学生版一个月9.5元。</li>
<li>python3。</li>
<li>radicale，使用python3编写的caldav服务器程序。</li>
</ol>
<h3 id="步骤一览"><a href="#步骤一览" class="headerlink" title="步骤一览:"></a>步骤一览:</h3><ol>
<li>云服务器购买与登录</li>
<li>安全组设置</li>
<li>Python3环境</li>
<li>安装radicale</li>
<li>配置radicale</li>
</ol>
<hr>
<h3 id="云服务器准备"><a href="#云服务器准备" class="headerlink" title="云服务器准备"></a>云服务器准备</h3><p>购买与登录的流程就自己搜索吧。我购买的是Ubunt的主机，也可以使用CentOS。</p>
<p>需要注意的是在创建服务器实例之前，最好先将本机的ssh public key导入到阿里云中，并且新建实例后选择该public key，不然不能够在终端中登录，而阿里云提供的浏览器vnc完全不能用。也可以在创建实例后再创建public key，只是需要重启实例罢了。</p>
<h3 id="安全组设置"><a href="#安全组设置" class="headerlink" title="安全组设置"></a>安全组设置</h3><p>阿里云默认关闭大多数端口，包括了我们这次要使用到的5232端口。所以请自行搜索“阿里云 安全组 端口开启“完成该步骤。</p>
<h3 id="Python3的环境搭建"><a href="#Python3的环境搭建" class="headerlink" title="Python3的环境搭建"></a>Python3的环境搭建</h3><p>这一步大体上也是请搜索“Ubuntu python3“</p>
<p>需要注意的是先使用<code>sudo apt-get update</code>更新本地软件目录。</p>
<h3 id="安装radicale"><a href="#安装radicale" class="headerlink" title="安装radicale"></a>安装radicale</h3><p>这一步会很详细的讲。</p>
<p>安装radicale</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">python3 -m pip install --upgrade radicale</span><br></pre></td></tr></table></figure>

<p>若是在本地使用，可以使用下面这个命令。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">python3 -m radicale --config "" --storage-filesystem-folder=~/.var/lib/radicale/collections</span><br></pre></td></tr></table></figure>

<p>然后访问 <a href="http://localhost:5232" target="_blank" rel="noopener">http://localhost:5232</a></p>
<p>但是若在服务器上访问就无法访问。需要配置参数。</p>
<p>我使用的配置有，把配置文件放在<code>/etc/radicale/config</code></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[server]</span><br><span class="line"># Bind all addresses</span><br><span class="line">hosts = 0.0.0.0:5232</span><br><span class="line">daemon = True</span><br><span class="line">[auth]</span><br><span class="line">type = htpasswd</span><br><span class="line">htpasswd_filename = /etc/radicale/users</span><br><span class="line">htpasswd_encryption = plain</span><br><span class="line">[storage]</span><br><span class="line">filesystem_folder = ~/.var/lib/radicale/collections</span><br></pre></td></tr></table></figure>

<p>想详细了解更多配置选项可以查看<a href="https://radicale.org/configuration/" target="_blank" rel="noopener">configuration</a></p>
<p>然后可以设置用户名和密码, 把配置文件放在<code>/etc/radicale/users</code></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">user:password</span><br></pre></td></tr></table></figure>

<p>然后启动就好了。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">python3 -m radicale</span><br></pre></td></tr></table></figure>

<p>正常访问。</p>
<p>然后在2Do的配置上选择就好了。</p>
<p><img src="http://ww4.sinaimg.cn/large/006y8mN6gy1g79utaszl2j313a0tu4en.jpg" alt="2do"></p>
]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>软件测试week2 note</title>
    <url>/2019/09/16/%E8%BD%AF%E4%BB%B6%E6%B5%8B%E8%AF%95week2-note/</url>
    <content><![CDATA[<h2 id="Fault-failure-and-error"><a href="#Fault-failure-and-error" class="headerlink" title="Fault, failure and error"></a>Fault, failure and error</h2><p>example</p>
<h2 id="为什么软件测试变得越来越重要？"><a href="#为什么软件测试变得越来越重要？" class="headerlink" title="为什么软件测试变得越来越重要？"></a>为什么软件测试变得越来越重要？</h2><h2 id="测试过程的成熟等级"><a href="#测试过程的成熟等级" class="headerlink" title="测试过程的成熟等级"></a>测试过程的成熟等级</h2><p>Level 0</p>
<p>Level 1</p>
<p>Level 2</p>
<p>Level 3</p>
<p>Level 4</p>
<h2 id="每一个测试的目的是什么？"><a href="#每一个测试的目的是什么？" class="headerlink" title="每一个测试的目的是什么？"></a>每一个测试的目的是什么？</h2><h2 id="什么时候开始测试？"><a href="#什么时候开始测试？" class="headerlink" title="什么时候开始测试？"></a>什么时候开始测试？</h2><h2 id="不测试的代价？"><a href="#不测试的代价？" class="headerlink" title="不测试的代价？"></a>不测试的代价？</h2><h2 id="我们为何要测试软件？"><a href="#我们为何要测试软件？" class="headerlink" title="我们为何要测试软件？"></a>我们为何要测试软件？</h2><h2 id="软件活动中的测试等级"><a href="#软件活动中的测试等级" class="headerlink" title="软件活动中的测试等级"></a>软件活动中的测试等级</h2><h2 id="软件的可测试性（Software-Testability）"><a href="#软件的可测试性（Software-Testability）" class="headerlink" title="软件的可测试性（Software Testability）"></a>软件的可测试性（Software Testability）</h2><h2 id="可观测性和可控制性（Observability-and-Controllability）"><a href="#可观测性和可控制性（Observability-and-Controllability）" class="headerlink" title="可观测性和可控制性（Observability and Controllability）"></a>可观测性和可控制性（Observability and Controllability）</h2><h2 id="一个测试样例的组成部分"><a href="#一个测试样例的组成部分" class="headerlink" title="一个测试样例的组成部分"></a>一个测试样例的组成部分</h2><h2 id="自动化测试框架"><a href="#自动化测试框架" class="headerlink" title="自动化测试框架"></a>自动化测试框架</h2><p>Junit</p>
<h2 id="Hamcrest-Common-Matchers"><a href="#Hamcrest-Common-Matchers" class="headerlink" title="Hamcrest Common Matchers"></a>Hamcrest Common Matchers</h2><h2 id="如何测试标准输出中的字符串？"><a href="#如何测试标准输出中的字符串？" class="headerlink" title="如何测试标准输出中的字符串？"></a>如何测试标准输出中的字符串？</h2><h2 id="如何测试Main方法？"><a href="#如何测试Main方法？" class="headerlink" title="如何测试Main方法？"></a>如何测试Main方法？</h2>]]></content>
  </entry>
  <entry>
    <title>软件测试week3 note</title>
    <url>/2019/09/16/%E8%BD%AF%E4%BB%B6%E6%B5%8B%E8%AF%95week3-note/</url>
    <content><![CDATA[]]></content>
  </entry>
  <entry>
    <title>阅读日报20190911</title>
    <url>/2019/09/11/%E9%98%85%E8%AF%BB%E6%97%A5%E6%8A%A520190911/</url>
    <content><![CDATA[<h1 id="神经网络"><a href="#神经网络" class="headerlink" title="神经网络"></a>神经网络</h1><p><a href="https://www.cnblogs.com/subconscious/p/5058741.html" target="_blank" rel="noopener">神经网络浅讲：从神经元到深度学习</a></p>
<p>对于神经网络，大神级别的导读和总结。</p>
<p>不说了，去抄文中提到的概念去了。</p>
<p>话说软件工程的项目用到的车牌识别技术EasyPR还是此文作者开发的呀。</p>
]]></content>
      <tags>
        <tag>阅读日报</tag>
      </tags>
  </entry>
  <entry>
    <title>重建博客</title>
    <url>/2019/09/08/%E9%87%8D%E5%BB%BA%E5%8D%9A%E5%AE%A2/</url>
    <content><![CDATA[<p>2019年4月的时候用hexo和github page创建过一个博客，但是在更换电脑的时候意外丢失了模版。后又恢复回来，只剩下了网页，，没有网站配置和md原始文件。</p>
]]></content>
  </entry>
  <entry>
    <title>Kaldi入门(一):yesno项目</title>
    <url>/2020/05/01/Kaldi%E5%85%A5%E9%97%A8-%E4%B8%80-yesno%E9%A1%B9%E7%9B%AE/</url>
    <content><![CDATA[<p>这个学期选了一门自然语言处理课，结果这门课主要的研究课题是自动语音识别（ASR）。既然入了这个坑。就先好好了解一下如何做ASR吧。<br>老师Tom Ko要求使用Kaldi这个工具来做ASR。课上到一半才知道Kaldi中有几千行的脚本代码是老师提交的。好吧，脚本好难的。<br>为了入门Kaldi，课程的第5次Lab是一个mini projec: yesno</p>
<p>首先要下载并编译Kaldi，安装的过程不是我的学习重点，可以先参考<a href="[https://blog.csdn.net/snowdroptulip/article/details/78896915](https://blog.csdn.net/snowdroptulip/article/details/78896915)">Kaldi的下载安装与编译</a>，在漫长的编译过程之后假设已经安装好了Kaldi。</p>
<h2 id="项目目录结构"><a href="#项目目录结构" class="headerlink" title="项目目录结构"></a>项目目录结构</h2><p>yesno项目的脚本和README都在<code>kaldi/egs/yesno</code>之下。<br>README.txt文件中包含数据集描述：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">The "yesno" corpus is a very small dataset of recordings of one individual</span><br><span class="line">saying yes or no multiple times per recording, in Hebrew.  It is available from</span><br><span class="line">http://www.openslr.org/1.</span><br><span class="line">It is mainly included here as an easy way to test out the Kaldi scripts.</span><br><span class="line"></span><br><span class="line">The test set is perfectly recognized at the monophone stage, so the dataset is</span><br><span class="line">not exactly challenging.</span><br><span class="line"></span><br><span class="line">The scripts are in s5/.</span><br></pre></td></tr></table></figure>

<p>数据脚本路径： kaldi/egs/yesno/s5。在下面执行的很多操作都可以直接调用已经写好的脚本来执行，之所以深入到具体的流程中是为了加强对ASR流程的理解。</p>
<h2 id="下载数据集"><a href="#下载数据集" class="headerlink" title="下载数据集"></a>下载数据集</h2><p>第一步是从网络上下载数据集文件<code>waves_yesno.tar.gz</code>到s5/路径下并解压。<br>原始的数据是60个.wav文件。文件名是八个用下划线分隔的01组合。需要将音频数据转化成kaldi能够处理的格式。</p>
<h2 id="转换成Kaldi能处理的格式"><a href="#转换成Kaldi能处理的格式" class="headerlink" title="转换成Kaldi能处理的格式"></a>转换成Kaldi能处理的格式</h2><p>下载完数据集后，将数据集划分为31个训练，30个测试（数量大致相当）。在s5/下创建data文件夹，把划分好的音频文件放入train_yesno和test_yesno。</p>
<p>Kaldi使用以下几个文件来表示数据：</p>
<ol>
<li><p>Text<br>音频的文本记录。每一个音频文件一行。格式为<code>&lt;utt_id&gt; &lt;transcript&gt;</code>。<utt_id>为音频的id，一般用不带扩展名的文件名表示。utt_id在wav.scp文件中与具体的文件映射。<transcript>是音频对应的文字。</transcript></utt_id></p>
</li>
<li><p>wav.scp<br>将文件映射到唯一的utt_id。<br>格式为<code>&lt;utt_id&gt; &lt;path or command to get wave file&gt;</code><br>第二个参数既可以是对应utt_id的音频文件路径，也可以是能够获得音频文件的指令。</p>
</li>
<li><p>utt2spk<br>对于每一个音频文件，标记是哪一个人发音的。因为yesno数据集中只有一个发音者，用global来表示所有的utt_id<br>文件内每一行的格式为<code>&lt;utt_id&gt; &lt;speaker_id&gt;</code></p>
</li>
<li><p>spk2utt<br>和3反过来。文件内每一行对应一个发音者，第一个是speaker的id，后面用空格分隔开60个utt_id。格式为<code>&lt;speaker_id&gt; &lt;utt_id1&gt; &lt;utt_id2&gt; ...</code></p>
</li>
</ol>
<p>本步骤可直接调用脚本：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> kaldi/egs/yesno/s5</span><br><span class="line"><span class="built_in">local</span>/prepare_data.sh waves_yesno</span><br></pre></td></tr></table></figure>

<p>读了一下prepare_data.sh的脚本</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/usr/bin/env bash</span></span><br><span class="line"></span><br><span class="line">mkdir -p data/<span class="built_in">local</span></span><br><span class="line"><span class="built_in">local</span>=`<span class="built_in">pwd</span>`/<span class="built_in">local</span></span><br><span class="line">scripts=`<span class="built_in">pwd</span>`/scripts</span><br><span class="line"></span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:`<span class="built_in">pwd</span>`/../../../tools/irstlm/bin</span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"Preparing train and test data"</span></span><br><span class="line"></span><br><span class="line">train_base_name=train_yesno</span><br><span class="line">test_base_name=test_yesno</span><br><span class="line">waves_dir=<span class="variable">$1</span></span><br><span class="line"></span><br><span class="line">ls -1 <span class="variable">$waves_dir</span> &gt; data/<span class="built_in">local</span>/waves_all.list</span><br><span class="line"></span><br><span class="line"><span class="built_in">cd</span> data/<span class="built_in">local</span></span><br><span class="line"></span><br><span class="line">../../<span class="built_in">local</span>/create_yesno_waves_test_train.pl waves_all.list waves.test waves.train</span><br><span class="line"></span><br><span class="line">../../<span class="built_in">local</span>/create_yesno_wav_scp.pl <span class="variable">$&#123;waves_dir&#125;</span> waves.test &gt; <span class="variable">$&#123;test_base_name&#125;</span>_wav.scp</span><br><span class="line"></span><br><span class="line">../../<span class="built_in">local</span>/create_yesno_wav_scp.pl <span class="variable">$&#123;waves_dir&#125;</span> waves.train &gt; <span class="variable">$&#123;train_base_name&#125;</span>_wav.scp</span><br><span class="line"></span><br><span class="line">../../<span class="built_in">local</span>/create_yesno_txt.pl waves.test &gt; <span class="variable">$&#123;test_base_name&#125;</span>.txt</span><br><span class="line"></span><br><span class="line">../../<span class="built_in">local</span>/create_yesno_txt.pl waves.train &gt; <span class="variable">$&#123;train_base_name&#125;</span>.txt</span><br><span class="line"></span><br><span class="line">cp ../../input/task.arpabo lm_tg.arpa</span><br><span class="line"></span><br><span class="line"><span class="built_in">cd</span> ../..</span><br><span class="line"></span><br><span class="line"><span class="comment"># This stage was copied from WSJ example</span></span><br><span class="line"><span class="keyword">for</span> x <span class="keyword">in</span> train_yesno test_yesno; <span class="keyword">do</span></span><br><span class="line">  mkdir -p data/<span class="variable">$x</span></span><br><span class="line">  cp data/<span class="built_in">local</span>/<span class="variable">$&#123;x&#125;</span>_wav.scp data/<span class="variable">$x</span>/wav.scp</span><br><span class="line">  cp data/<span class="built_in">local</span>/<span class="variable">$x</span>.txt data/<span class="variable">$x</span>/text</span><br><span class="line">  cat data/<span class="variable">$x</span>/text | awk <span class="string">'&#123;printf("%s global\n", $1);&#125;'</span> &gt; data/<span class="variable">$x</span>/utt2spk</span><br><span class="line">  utils/utt2spk_to_spk2utt.pl &lt;data/<span class="variable">$x</span>/utt2spk &gt;data/<span class="variable">$x</span>/spk2utt</span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure>

<h2 id="建立词典"><a href="#建立词典" class="headerlink" title="建立词典"></a>建立词典</h2><p>对于当前项目，我们只有两个词 Ken(yes) 和 Lo（no)。但是在真实的语言中，词的数量不可能这么少，并且还有停顿和环境噪声。kaldi将这些非语言的声音称作slience（SIL）。<br>加上SIL一共需要三个词来表示当前这个yesno语言模型。</p>
<p>调用脚本：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">local</span>/prepare_dict.sh</span><br></pre></td></tr></table></figure>

<p>将会在s5/data/local/dict中看到新生成的5个文件。</p>
<ol>
<li><p>lexicon.txt</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;SIL&gt; SIL</span><br><span class="line">YES Y</span><br><span class="line">NO N</span><br></pre></td></tr></table></figure>
</li>
<li><p>lexicon_words.txt<br>比1少第一行</p>
</li>
<li><p>nonsilence_phones.txt</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Y</span><br><span class="line">N</span><br></pre></td></tr></table></figure>
</li>
<li><p>silence_phones.txt</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SIL</span><br></pre></td></tr></table></figure>
</li>
<li><p>optional_silence.txt<br>和4一样</p>
</li>
</ol>
<p>这个脚本本身只是将input文件夹下面的lexicon_nosil.txt，lexicon.txt， phones.txt复制到dict所在目录，并且加上SIL。</p>
<h2 id="语言模型"><a href="#语言模型" class="headerlink" title="语言模型"></a>语言模型</h2><p>接下来要做语言模型。<br>项目提供了一个一元的语言模型。然而我们需要将这个模型转换成一个WFST（一种有穷自动机）<br>执行:<br> <figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">utils/prepare_lang.sh --position-dependent-phones <span class="literal">false</span> data/<span class="built_in">local</span>/dict/ <span class="string">"&lt;SIL&gt;"</span> data/<span class="built_in">local</span>/lang/ data/lang</span><br><span class="line"><span class="built_in">local</span>/prepare_lm.sh</span><br></pre></td></tr></table></figure></p>
<p>prepare_lang.sh的开头注释如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># This script prepares a directory such as data/lang/, in the standard format,</span><br><span class="line"># given a source directory containing a dictionary lexicon.txt in a form like:</span><br><span class="line"># word phone1 phone2 ... phoneN</span><br><span class="line"># per line (alternate prons would be separate lines), or a dictionary with probabilities</span><br><span class="line"># called lexiconp.txt in a form:</span><br><span class="line"># word pron-prob phone1 phone2 ... phoneN</span><br><span class="line"># (with 0.0 &lt; pron-prob &lt;= 1.0); note: if lexiconp.txt exists, we use it even if</span><br><span class="line"># lexicon.txt exists.</span><br><span class="line"># and also files silence_phones.txt, nonsilence_phones.txt, optional_silence.txt</span><br><span class="line"># and extra_questions.txt</span><br><span class="line"># Here, silence_phones.txt and nonsilence_phones.txt are lists of silence and</span><br><span class="line"># non-silence phones respectively (where silence includes various kinds of</span><br><span class="line"># noise, laugh, cough, filled pauses etc., and nonsilence phones includes the</span><br><span class="line"># &quot;real&quot; phones.)</span><br><span class="line"># In each line of those files is a list of phones, and the phones on each line</span><br><span class="line"># are assumed to correspond to the same &quot;base phone&quot;, i.e. they will be</span><br><span class="line"># different stress or tone variations of the same basic phone.</span><br><span class="line"># The file &quot;optional_silence.txt&quot; contains just a single phone (typically SIL)</span><br><span class="line"># which is used for optional silence in the lexicon.</span><br><span class="line"># extra_questions.txt might be empty; typically will consist of lists of phones,</span><br><span class="line"># all members of each list with the same stress or tone; and also possibly a</span><br><span class="line"># list for the silence phones.  This will augment the automatically generated</span><br><span class="line"># questions (note: the automatically generated ones will treat all the</span><br><span class="line"># stress/tone versions of a phone the same, so will not &quot;get to ask&quot; about</span><br><span class="line"># stress or tone).</span><br></pre></td></tr></table></figure>

<p>通过阅读脚本和脚本中的注释。可以知道<code>prepare_lang.sh</code>的用法</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Usage: utils/prepare_lang.sh &lt;dict-src-dir&gt; &lt;oov-dict-entry&gt; &lt;tmp-dir&gt; &lt;lang-dir&gt;</span><br><span class="line">e.g.: utils/prepare_lang.sh data/local/dict &lt;SPOKEN_NOISE&gt; data/local/lang data/lang</span><br><span class="line">--position-dependent-phones (true|false)        # default: true; if true, use _B, _E, _S &amp; _I</span><br></pre></td></tr></table></figure>

<p><dict-src-dir>是我们在上一部分生成的词典目录。需要包含lexico.txt，extra_questions.txt，nonsilence_phones.txt，optional_silence.txt  silence_phones.txt。<br><code>position_dependent_phones</code>参数为false，导致解码后不能算出单词边界。很多的脚本，特别是评分脚本将不能正常运行。<br>第二个指令将语言模型转换成G.fst格式并保存在data/lang_test_tg 目录下。<br>这个脚本的核心内容是调用了arpa2fst和fstisstochastic，再创建了G.fst之后检查是否有空字符（<s>,</s>之类的）的循环。</dict-src-dir></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">arpa2fst --disambig-symbol=#0 --read-symbol-table=$test/words.txt input/task.arpabo $test/G.fst</span><br><span class="line"></span><br><span class="line">fstisstochastic $test/G.fst</span><br></pre></td></tr></table></figure>

<p><a href="https://blog.csdn.net/yutianzuijin/article/details/78756130" target="_blank" rel="noopener">arpa2fst 原理详解</a></p>
<blockquote>
<p>arpa文件可以很容易地表示任意n-gram语言模型，不过在实际中n通常等于3、4或者5。arpa文件的每一行表示一个文法项，它通常包含三部分内容：probability word(s) [backoff probability]。probability表示该词或词组发生的概率，word(s)表示具体的词或者词组。backoff probablitiy是可选项，表示回退概率。</p>
</blockquote>
<p>在yesno这个toy project中只使用1元的语言模型。对应的arpa文件在<code>input/task.arpabo</code></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">\data\</span><br><span class="line">ngram 1=4</span><br><span class="line"></span><br><span class="line">\1-grams:</span><br><span class="line">-1	NO</span><br><span class="line">-1	YES</span><br><span class="line">-99 &lt;s&gt;</span><br><span class="line">-1 &lt;/s&gt;</span><br><span class="line"></span><br><span class="line">\end\</span><br></pre></td></tr></table></figure>

<p>fstisstochastic命令则如同其名字的含义一样，用来检查G.fst是否是随机的。<br>在<code>s5/data/lang</code>目录下会出现：</p>
<ol>
<li><p><code>phones.txt</code>:将phone转换成数字。其中#0，#1是空字，用来表示句子的开头和结尾。<eps> 是一个特别的含义表示这个弧上没有符号。</eps></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;eps&gt; 0</span><br><span class="line">SIL 1</span><br><span class="line">Y 2</span><br><span class="line">N 3</span><br><span class="line">#0 4</span><br><span class="line">#1 5</span><br></pre></td></tr></table></figure>
</li>
<li><p><code>words.txt</code></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;eps&gt; 0</span><br><span class="line">&lt;SIL&gt; 1</span><br><span class="line">NO 2</span><br><span class="line">YES 3</span><br><span class="line">#0 4</span><br><span class="line">&lt;s&gt; 5</span><br><span class="line">&lt;/s&gt; 6</span><br></pre></td></tr></table></figure>
</li>
<li><p><code>L_disambig.fst, L.fs</code>t: the dict can be recognized by Kaldi</p>
</li>
<li><p><code>topo</code>: phone states transition(HMM)</p>
</li>
<li><p><code>oov</code>: out of vocabulary. 仅包含<code>&lt;SIL&gt;</code></p>
</li>
<li><p><code>phones</code>: some information about phones</p>
</li>
</ol>
<h2 id="特征提取和训练"><a href="#特征提取和训练" class="headerlink" title="特征提取和训练"></a>特征提取和训练</h2><p>MFCC特征提取和GMM-HMM建模</p>
<p>提取梅尔倒谱系数</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">steps/make_mfcc.sh --nj $num $input_dir $log_dir $output_dir</span><br></pre></td></tr></table></figure>

<p><a href="https://zhuanlan.zhihu.com/p/60371062" target="_blank" rel="noopener">语音信号处理（二）—— MFCC详解</a><br>梅尔倒谱系数是一种非线性的时频表示法，其应用了人耳对低频声音的听觉敏感度更高的原理。</p>
<p>接着正则化倒谱特征</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">steps/compute_cmvn_stats.sh </span><br><span class="line">utils/fix_data_dir.sh $input_dir</span><br></pre></td></tr></table></figure>

<p><a href="http://placebokkk.github.io/kaldi/2019/08/05/asr-kaldi-feat2.html" target="_blank" rel="noopener">Kaldi中的特征提取(二）- 特征变换</a><br>对训练集和测试集做同样的操作。<br>这里我采用的参数是 $num=1 $output_dir=mfcc<br>那么结果将会保存在mfcc文件夹下。<br>cmvn_test_yesno.ark  cmvn_test_yesno.scp  cmvn_train_yesno.ark  cmvn_train_yesno.scp。<br>ark文件包含特征向量（用cat打开是乱码），scp文件是关系文件，从发音者到ark文件的对应。<br>也可以直接跑脚本：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">num=1 </span><br><span class="line">output_dir=mfcc</span><br><span class="line">for x in train_yesno test_yesno; do</span><br><span class="line">  steps/make_mfcc.sh --nj 1 data/$x exp/make_mfcc/$x mfcc  </span><br><span class="line">  steps/compute_cmvn_stats.sh data/$x exp/make_mfcc/$x mfcc        </span><br><span class="line">  utils/fix_data_dir.sh data/$x </span><br><span class="line">done</span><br></pre></td></tr></table></figure>

<h2 id="单音素模型训练"><a href="#单音素模型训练" class="headerlink" title="单音素模型训练"></a>单音素模型训练</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">steps/train_mono.sh —nj $N —cmd $MAIN_CMD $DATA_DIR $LANG_DIR $OUTPUT_DIR</span><br></pre></td></tr></table></figure>

<p>参数说明：<br>—nj：job的数量，来自同一个speaker的语音不能并行处理。所以在本项目中只能选择为1。<br>—cmd：为了使用本机的资源，调用”utils/run.pl”</p>
<p>运行脚本：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">train_cmd=&quot;utils/run.pl&quot; steps/train_mono.sh --nj 1 --cmd &quot;$train_cmd&quot; \   </span><br><span class="line">--totgauss 400 \   </span><br><span class="line">data/train_yesno data/lang exp/mono0a</span><br></pre></td></tr></table></figure>

<p>到现在我们已经完成了模型的训练。</p>
<h2 id="解码和测试"><a href="#解码和测试" class="headerlink" title="解码和测试"></a>解码和测试</h2><p>接下来用测试集来验证一下模型的准确与否。<br>第一步是创建一个全连接的FST网络。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">utils/mkgraph.sh data/lang_test_tg exp/mono0a exp/mono0a/graph_tgpr</span><br></pre></td></tr></table></figure>

<p>这个指令背后的脚本很长。基本上做的事情是创建以一个HCLG（HMM+Context+Lexicon+Grammer）的解码器并保存在exp/mono0a/graph_tgpr中。<br>还记得我们的每一条语音都是8个连续的Ken或Lo吗(Ken，Lo是希伯来语的yes no）?训练好的模型的工作就是找出这8个词的顺序。<br><code>steps/decode.sh [options] &lt;graph-dir&gt; &lt;data-dir&gt; &lt;decode-dir&gt;</code>用来寻找每一个测试音频的最佳路径</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">decode_cmd=&quot;utils/run.pl&quot; steps/decode.sh --nj 1 --cmd &quot;$decode_cmd&quot; \</span><br><span class="line">exp/mono0a/graph_tgpr data/test_yesno exp/mono0a/decode_test_yesno</span><br></pre></td></tr></table></figure>

<p>最后是查看结果的环节。<br>在decode.sh内部最后会调用score.sh，这个脚本则生成预测的结果并且计算测试集Word error rate（WER）。<br>调用下列命令可以看到最好的效果：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">for x in exp/*/decode*; do [ -d $x ] &amp;&amp; grep WER $x/wer_* | utils/best_wer.sh;</span><br><span class="line">done</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">%WER 0.00 [ 0 / 232, 0 ins, 0 del, 0 sub ] exp/mono0a/decode_test_yesno/wer_10_0.0</span><br></pre></td></tr></table></figure>

<p>解读一下结果，花了很长时间才弄懂这些东西是什么意思。<br>WER后跟着的0.00是说字的错误率为0，即准确率为100%。<br>测试集一共29条音频，每条音频有8个字（单音素的字）。一共232个字。<br>参考Stanford的cs224s-17.lec04.pdf</p>
<p><img src="https://upload-images.jianshu.io/upload_images/4328467-dc5c0fcaf24b3750.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="WER的计算方法"><br><img src="https://upload-images.jianshu.io/upload_images/4328467-1c85e0672f7772cb.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt><br>而wer结果文件中的10和0.0分别是lmwt(Language Weight)和wip(word insertion penalty，词插入惩罚)。lmwt用来平衡LM（语言模型）在多大程度上帮助AM（语音模型）<img src="https://upload-images.jianshu.io/upload_images/4328467-3e2341231bb987fa.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="LMWT用途 
https://skemman.is/bitstream/1946/31280/1/msc_anna_vigdis_2018.pdf"><br>至于<a href="https://www.zhihu.com/question/31416764/answer/353868805" target="_blank" rel="noopener">wip</a>：</p>
<blockquote>
<p>word insertion penalty, 简写WIP, 是HMM识别匹配过程中用于设置句长的一个参数，可以用来调节生成句子中的单词个数，当前主流的语音识别系统主要采用的都是音素识别，即根据单词的音标而不是单词来进行匹配，这就导致了，在识别过程中，可能很难确定单词的gap，如果让系统自由识别，根据参数初始化的模型来进行匹配的话有可能会生成一些诡异的由长单词构成的句子，或者有很多短单词构成的句子，这些匹配率很低的句子对HMM参数的优化作用很小，同时也很大概率会导致学习速率奇慢或者局部最优解这样的问题，所以通过设置这个参数来得到一些更符合语义结构的生成片段。</p>
</blockquote>
<p>最后，我们调用的所有脚本都在run.sh中。</p>
]]></content>
      <tags>
        <tag>Kaldi</tag>
        <tag>ASR</tag>
      </tags>
  </entry>
  <entry>
    <title>Kaldi入门(二):AiShell(上)</title>
    <url>/2020/05/01/Kaldi%E5%85%A5%E9%97%A8-%E4%BA%8C-AiShell-%E4%B8%8A/</url>
    <content><![CDATA[<p>这篇文章是学习Kaldi的第二篇。对应SUSTech CS310课程的Lab6和Lab7。<br>第一篇里探索了如何对toy language（仅包含两个单音素单词）进行语言模型的建模。至于训练和解码的部分，时间条件和理解能力暂时不允许去整理。<br>本篇文章的主要目标是理解复杂的中文多音素语言模型和使用AiShell语料集来真实的训练出一个可用的中文语音识别模型。完整的AiShell例子包含GMM-HMM和神经网络。Lab6先展示了GMM-HMM后的结果。Lab7则补充了神经网络。</p>
<h2 id="AiShell描述和下载"><a href="#AiShell描述和下载" class="headerlink" title="AiShell描述和下载"></a>AiShell描述和下载</h2><p>AiShell 是 希尔贝壳公司开源的中文普通话语料集。400个来自不同方言区的人参与录制， 录制的条件是在室内使用高保真的麦克风，音频降采样到16000Hz。中文文字脚本95%的准确度。170小时的语料。划分为85%的训练集，10%的开发集（作用？），5%的测试集。在上课的时候我被录制语料的成本吓到了，2000小时的语料大约需要100万人民币的费用。AiShell语料集可以免费用于学术目的。</p>
<p>Kaldi中包含Aishell的示例脚本。在<code>kaldi/egs/aishell/s5</code>中。下文所有的文件都在该目录之下。<br>下载语料集的脚本包含在<code>run.sh</code>中。<br>先安装好语言模型的工具才能运行<code>run.sh</code></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">run ./install_kaldi_lm.sh &amp;&amp; source ../env.sh</span><br></pre></td></tr></table></figure>

<p>上一篇文章没有说每一个项目下的s5文件夹中有什么，在网上找到了别人写的一个总结：<a href="https://www.jianshu.com/p/6ab663601da8" target="_blank" rel="noopener">kaldi 源码分析(三) - run.pl 分析</a></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cmd.sh                     # 并行执行命令，通常分 run.pl, queue.pl 两种</span><br><span class="line">config                       # 参数定制化配置文件， mfcc, decode, cmvn 等配置文件</span><br><span class="line">local                         # 工程定制化内容</span><br><span class="line">path.sh                    # 环境变量相关脚本</span><br><span class="line">run.sh                      # 整体流程控制脚本，主入口脚本</span><br><span class="line">steps                       # 存放单一步骤执行的脚本</span><br><span class="line">utils                         # 存放解析文件，预处理等相</span><br><span class="line">关工具的脚本</span><br></pre></td></tr></table></figure>

<p>最重要的入口脚本是run.sh。包含所有脚本。如果要在本地运行，需要修改这个脚本。把其中的<code>queue.pl</code>改成<code>run.pl</code>。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">export train_cmd=&quot;run.pl&quot; </span><br><span class="line">export decode_cmd=run.pl </span><br><span class="line">export mkgraph_cmd=&quot;run.pl&quot;</span><br></pre></td></tr></table></figure>

<p>先做Lab6，注释掉神经网络训练部分。为了对比加不加神经网络对最后的识别准确率有多大的影响。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># nnet3</span><br><span class="line">#local/nnet3/run_tdnn.sh</span><br><span class="line"># chain</span><br><span class="line">#local/chain/run_tdnn.sh</span><br></pre></td></tr></table></figure>

<h2 id="运行run-sh脚本，一步到位"><a href="#运行run-sh脚本，一步到位" class="headerlink" title="运行run.sh脚本，一步到位"></a>运行run.sh脚本，一步到位</h2><p>在上一篇文章中，主要讲了kaldi的工作流程，复杂一点的项目除了要考虑多音素的对齐以外？基本流程是差不多的。先运行整体流程脚本run.sh看一下效果。然后再具体深入进脚本中看有哪些关键步骤。</p>
<p>你是否遇到过连接远程服务器跑训练，然后网络掉线杀掉了正在跑的进程？我遇到过，后来主要使用nohup来避免这个问题。课件里推荐使用screen来避免远程登陆进程被杀掉后，训练进程也停止的问题。screen的原理不是本篇文章关心的重点。<br>加上screen后运行run.sh：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">screen -S run</span><br><span class="line">run ./run.sh</span><br></pre></td></tr></table></figure>

<p>就能看到脚本在一个新的页面输出内容了。<br>如果要结束进程<code>ctrl a + d</code>//我其实不喜欢这个命令，因为很经常使用ctrl+a来编辑命令，两个快捷键冲突。</p>
<h2 id="查看结果"><a href="#查看结果" class="headerlink" title="查看结果"></a>查看结果</h2><p>中文语音识别的准确度通常使用CER（Char Error Rate）来表示。因为中文中字是最小语义单位，而英文中词是基本语义单位。<br>和上一篇文章差不多的命令。脚本的运行结果保存在了exp目录下。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">for x in exp/*/decode_test; do [ -d $x ] &amp;&amp; grep WER $x/cer_* | utils/best_wer.sh; done 2&gt;/dev/null</span><br></pre></td></tr></table></figure>

<p>训练出来的结果如下：<br><img src="https://upload-images.jianshu.io/upload_images/4328467-1d97f79d32a17c9d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="训练结果"></p>
<p>可以<code>cat RESULTS</code>，和官方跑出来的结果做一下对比。<br><img src="https://upload-images.jianshu.io/upload_images/4328467-9e126dc0a774d7e5.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="RESULTS"><br>需要注意的是，和上篇文章的实验不一样的是，输出的结果是多行的，因为执行了多次的实验，上面的脚本输出的是每次实验最好的结果。<br>我自己跑出来的最好结果是tri5a的cer_14_0.5而RESULTS中的GMM-HMM模型中最好的结果是tri5a的cer_13_0.5。两者CER都是12.12。每次实验本身都有一定的随机性。结果有一些误差是没问题的。为了确认模型有被正确的训练，查看自己结果的<code>tri5a/decode_test/cer_13_0.5</code>的CER是12.18，恰好不是最优解而已。这里的13和14是lmwt（语言模型权重）。具体的可以看上一篇文章。<br><img src="https://upload-images.jianshu.io/upload_images/4328467-c66a0fed697e4d4e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="cer_13_0.5"></p>
<h2 id="细节"><a href="#细节" class="headerlink" title="细节"></a>细节</h2><p>使用命令<code>cat run.sh | grep &quot;#&quot;</code>将run.sh脚本中的环节注释提取打印出来。其中倒数2，4行是我们在一开始注释掉的。可以看到基本可以分为准备、训练和获取结果三个部分。<br><img src="https://upload-images.jianshu.io/upload_images/4328467-abf575a7096c5532.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="run.sh注释部分"></p>
<h3 id="准备"><a href="#准备" class="headerlink" title="准备"></a>准备</h3><ol>
<li>下载语料集<br>需要注意的是aishell语料集有大概20GB的大小。意味着需要很长的时间才能下载下来。我是直接用服务器里提前下好的语料集。<br><img src="https://upload-images.jianshu.io/upload_images/4328467-61ddf46d7f32ab25.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="aishell目录概览"><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">local/download_and_untar.sh $data $data_url data_aishell || exit 1;</span><br></pre></td></tr></table></figure>

</li>
</ol>
<p>这里的 <code>a || b</code>是一个逻辑符号，代表着如果a执行失败则执行b。这里要放一个小插曲。去年面试阿里云的实习项目时，面试官开头就问了如何知道上一条linux命令是否成功执行。我当时不知道，现在要知道了。就是看变量<code>$?</code>的值，如果为0代表成功执行。这里的<code>exit 1</code>终止当前进程并且将<code>$?</code>设置为1。表示不成功执行。<br><code>$data</code> 是aishell在本机的位置，既可以新建一个空目录来下载，也可以指定到已经下好的路径，aishell 分为<code>resource_aishell</code>和<code>data_aishell</code>两部分来下载，脚本会通过检查每一个部分下是否有<code>.complete</code>文件来判断当前部分是否下载完全。如果没有才会到指定网址下载。</p>
<ol start="2">
<li>Lexicon Preparation<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">local/aishell_prepare_dict.sh $data/resource_aishell || exit 1;</span><br></pre></td></tr></table></figure>

</li>
</ol>
<p>这个脚本的功能主要是将<code>resource_aishell</code>下的<code>lexicon.txt</code>复制到<code>data/local/dict</code>中。并且提取出<code>nonsilence_phones.txt</code>、<code>optional_silence.txt</code>、<code>silence_phones.txt</code>和<code>extra_questions.txt</code>。用到了很多awk和perl的脚本。没看懂。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/4328467-83063cfebc09aa40.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="lexicon.txt"></p>
<p><img src="https://upload-images.jianshu.io/upload_images/4328467-a3a4627506e1625c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="提取extra_questions.txt的代码"></p>
<p><img src="https://upload-images.jianshu.io/upload_images/4328467-7a4adb98d33170fe.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="extra_questions.txt部分内容"></p>
<p><img src="https://upload-images.jianshu.io/upload_images/4328467-5fec7d4dd70defd3.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="提取nonsilence_phones.txt代码"><br>每行代表一组相同的base phone,包含各种不同的重音或者声调。<br><img src="https://upload-images.jianshu.io/upload_images/4328467-910cf3e3056dac3d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="nonsilence_phones.txt部分内容"></p>
<ol start="3">
<li>Data preparation<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">local/aishell_data_prep.sh $data/data_aishell/wav $data/data_aishell/transcript || exit 1;</span><br></pre></td></tr></table></figure>

</li>
</ol>
<p><code>$data/data_aishell/wav</code>目录下放着的是音频文件。其中有两级目录<code>speaker/filename.wav</code>。<br><code>$data/data_aishell/transcript</code>目录下放着的是<code>aishell_transcript_v0.8.txt</code>文字翻录。<br>这个shell脚本的功能是将<code>$data/data_aishell/wav</code>下的 <code>train</code>,<code>test</code>,<code>dev</code>分别建立索引。并且建立Kaldi能够理解的语料格式。具体有些什么可以参考上一篇文章和下面这一段脚本。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># Transcriptions preparation</span><br><span class="line">for dir in $train_dir $dev_dir $test_dir; do</span><br><span class="line">  echo Preparing $dir transcriptions</span><br><span class="line">  # 将当前集合目录下的wav的文件名提取出来作为utt_id</span><br><span class="line">  sed -e &apos;s/\.wav//&apos; $dir/wav.flist | awk -F &apos;/&apos; &apos;&#123;print $NF&#125;&apos; &gt; $dir/utt.list</span><br><span class="line">  # 根据目录结构建立utt2spk的关系</span><br><span class="line">  sed -e &apos;s/\.wav//&apos; $dir/wav.flist | awk -F &apos;/&apos; &apos;&#123;i=NF-1;printf(&quot;%s %s\n&quot;,$NF,$i)&#125;&apos; &gt; $dir/utt2spk_all</span><br><span class="line">  # 按列合并utt.list和wav.flist，达到对音频文件的映射。</span><br><span class="line">  paste -d&apos; &apos; $dir/utt.list $dir/wav.flist &gt; $dir/wav.scp_all</span><br><span class="line">  utils/filter_scp.pl -f 1 $dir/utt.list $aishell_text &gt; $dir/transcripts.txt</span><br><span class="line">  awk &apos;&#123;print $1&#125;&apos; $dir/transcripts.txt &gt; $dir/utt.list</span><br><span class="line">  utils/filter_scp.pl -f 1 $dir/utt.list $dir/utt2spk_all | sort -u &gt; $dir/utt2spk</span><br><span class="line">  utils/filter_scp.pl -f 1 $dir/utt.list $dir/wav.scp_all | sort -u &gt; $dir/wav.scp</span><br><span class="line">  sort -u $dir/transcripts.txt &gt; $dir/text</span><br><span class="line">  utils/utt2spk_to_spk2utt.pl $dir/utt2spk &gt; $dir/spk2utt</span><br><span class="line">done</span><br></pre></td></tr></table></figure>

<h4 id="4-Phone-sets-questions-L-compilation"><a href="#4-Phone-sets-questions-L-compilation" class="headerlink" title="4. Phone sets, questions, L compilation"></a>4. Phone sets, questions, L compilation</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">utils/prepare_lang.sh --position-dependent-phones false data/local/dict \</span><br><span class="line">    &quot;&lt;SPOKEN_NOISE&gt;&quot; data/local/lang data/lang || exit 1;</span><br></pre></td></tr></table></figure>

<p>上面shell脚本的目的是创建L.fst，音素模型，其中fst是Finite State Transducers（有限状态转换器）的缩写。找到这篇<a href="https://blog.csdn.net/DuishengChen/article/details/52473918" target="_blank" rel="noopener">Kaldi学习笔记 – 构建字典FST脚本 – prepare_lang.sh 关键内容解析</a>详细的说明了这个脚本的工作。而<a href="https://blog.csdn.net/mengjianmuzi/article/details/99499343" target="_blank" rel="noopener">关于prepare_lang的一点理解</a>给脚本进行了一些翻译和注释。</p>
<blockquote>
<p><a href="https://www.jianshu.com/p/4ad2add56b25" target="_blank" rel="noopener">Kaldi中FST(Finite State Transducer)含义及其可视化</a><br>L.fst: 音素词典（Phonetic Dictionary or Lexicon）模型，phone symbols作为输入，word symbols作为输出，如图Figure 1所示。<br><img src="https://upload-images.jianshu.io/upload_images/4328467-4d7db0ea1fea45fe.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="Figure 1 L.fst结构"><br>L_disambig.fst是为了消除模棱两可（disambiguation）而引入的模型，表述为 the lexicon with disambiguation symbols。分歧的情况如：一个词是另一个词的前缀，cat 和 cats在同一个词典中，则需要”k ae t #1”； 有同音的词，red: “r eh d #1”, read: “r eh d #2”。</p>
</blockquote>
<p>我一直疑惑<code>lexiconp.txt</code>是怎么生成的，查了好久。结果竟然只是一段在词和音素之间插入1.0的代码：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">if [[ ! -f $srcdir/lexiconp.txt ]]; then</span><br><span class="line">  echo &quot;**Creating $srcdir/lexiconp.txt from $srcdir/lexicon.txt&quot;</span><br><span class="line">  perl -ape &apos;s/(\S+\s+)(.+)/$&#123;1&#125;1.0\t$2/;&apos; &lt; $srcdir/lexicon.txt &gt; $srcdir/lexiconp.txt || exit 1;</span><br><span class="line">fi</span><br></pre></td></tr></table></figure>

<p><img src="https://upload-images.jianshu.io/upload_images/4328467-03d9e641c2b5062c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="lexiconp.txt"><br>那么L.fst是怎么得到的呢？<br>通过<code>make_lexicon_fst.py</code>（现有的博客都说是.pl结尾，可能kaldi重构了）。还有一个消歧义的过程。具体的就看不懂了。<a href="https://shiweipku.gitbooks.io/chinese-doc-of-kaldi/content/decoding_graph_test.html" target="_blank" rel="noopener">解码图创建示例（测试阶段）</a>里有较为详细的文档讲解。</p>
<h4 id="5-LM-training"><a href="#5-LM-training" class="headerlink" title="5. LM training"></a>5. LM training</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">local/aishell_train_lms.sh || exit 1;</span><br></pre></td></tr></table></figure>

<p>这个shell脚本读取<code>data/local/train/text</code>,<code>data/local/dict/lexicon.txt</code><br>得到text的计数文件<code>word.counts</code>并以<code>word.counts</code>为基础添加<code>lexicon.txt</code>中的字（除了SIL）出现的次数到<code>unigram.counts</code>中。我就没深入看下去了，期间用到的脚本文件有:<code>get_word_map.pl</code>、<code>train_lm.sh --arpa --lmtype 3gram-mincount $dir || exit 1</code>;这个步骤的结果保存在<code>data/local/lm/3gram-mincount/lm_unpruned.gz</code>中。</p>
<h4 id="6-G-compilation-check-LG-composition"><a href="#6-G-compilation-check-LG-composition" class="headerlink" title="6. G compilation, check LG composition"></a>6. G compilation, check LG composition</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">utils/format_lm.sh data/lang data/local/lm/3gram-mincount/lm_unpruned.gz \</span><br><span class="line">    data/local/dict/lexicon.txt data/lang_test || exit 1;</span><br></pre></td></tr></table></figure>

<p>这个步骤是编译G.fst并将LG串联起来。</p>
<blockquote>
<p><a href="https://www.jianshu.com/p/4ad2add56b25" target="_blank" rel="noopener">Kaldi中FST(Finite State Transducer)含义及其可视化</a><br>G.fst: 语言模型，大部分是FSA（finite state acceptor, i.e. 每个arc的输入输出是相同的），如图Figure 2所示。<br><img src="//upload-images.jianshu.io/upload_images/9776212-21d8881fe6b03048.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/174/format/webp" alt="Figure 2 G.fst结构（由指令词识别1-gram语法产生，disambiguation symbol #0 未加入）
"></p>
</blockquote>
<blockquote>
<p><a href="https://hupeng.me/articles/25.html" target="_blank" rel="noopener">kaldi 训练 aishell 解析</a><br>utils/format_lm.sh:上述的语言工具基于第三方工具，为ARPA-format,脚本的作业是将其转换为fst，方便与之前的字典fst(L.fst)结合，发挥fst的优势。脚本最后会检测G.fst中是否存在没有单词的空回环，如果存在会报错，因为这会导致后续HLG determinization的出现错误。<br>脚本utils/format_lm.sh解决把ARPA格式的语言模型转换成OpenFST格式类型。脚本用法如下：<br>Usage: utils/format_lm.sh <lang_dir> <arpa-lm> <lexicon> <out_dir><br>E.g.: utils/format_lm.sh data/lang data/local/lm/foo.kn.gz data/local/dict/lexicon.txt data/lang_test<br>Convert ARPA-format language models to FSTs.<br>这个脚本的一些关键命令如下：<br>gunzip -c $lm <br>| arpa2fst –disambig-symbol=#0 <br>      –read-symbol-table=$out_dir/words.txt - $out_dir/G.fst<br>Kaldi程序arpa2fst将ARPA格式的语言模型转换成一个加权有限状态转移机（实际上是接收机）。</out_dir></lexicon></arpa-lm></lang_dir></p>
</blockquote>
<p>流程很复杂，未来可能再把L.fst，LM training，G.fst， LG composition另起一篇。（就是说现在时间条件不允许深入）</p>
<h3 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h3><p>训练的环节开始我就读不懂了。主要是逻辑和概念不懂。也不浪费时间了。简单的去了解一下输入输出和功能。</p>
<h4 id="1-MFCC-特征生成"><a href="#1-MFCC-特征生成" class="headerlink" title="1. MFCC 特征生成"></a>1. MFCC 特征生成</h4><p>这个环节和yesno项目的没有不同。主要就是获得train,test, dev三个集合的归一化的梅尔倒谱系数。最后修复排序错误，并会移除那些被指明需要特征数据或标注，但是却找不到被需要的数据的那些发音（utterances）。</p>
<h4 id="2-训练单音素模型"><a href="#2-训练单音素模型" class="headerlink" title="2. 训练单音素模型"></a>2. 训练单音素模型</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">steps/train_mono.sh --cmd &quot;$train_cmd&quot; --nj 10 \</span><br><span class="line">  data/train data/lang exp/mono || exit 1;</span><br></pre></td></tr></table></figure>

<p>参考<a href="https://zhuanlan.zhihu.com/p/82380716" target="_blank" rel="noopener">kaldi-GMM-HMM pipeline</a>，上面的shell脚本主要是对齐音素和每一帧音频的。<a href="https://blog.csdn.net/DanyHgc/article/details/75247158" target="_blank" rel="noopener">Kaldi 入门train_mono.sh详解</a>、<a href="https://blog.csdn.net/DuishengChen/article/details/52575926" target="_blank" rel="noopener">kaldi学习笔记 – 训练单音素（monophone）模型脚本 – steps/train_mono.sh</a>都有讲一些。<br>对流程讲得最好的是：<br>mkgraph 需要 lang_test 下的 L.fst G.fst phones.txt, words.txt , phones/silence.csl , phones/<a href="https://link.zhihu.com/?target=http%3A//disambig.int" target="_blank" rel="noopener">http://disambig.int</a></p>
<p>以及 exp/tri 下的 tree, final.mdl</p>
<blockquote>
<p>在训练的job并行训练过程中，训练数据的各个子集合是分散到不同的处理器去进行训练，然后每轮迭代后会进行合并。<br>下面就讲一下训练的过程：<br>1.首先是初始化GMM，使用的脚本是/kaldi-trunk/src/gmmbin/gmm-init-mono，输出是0.mdl和tree文件；<br>2.compile training graphs,使用的脚本是/kaldi-trunk/source/bin/compile-training-graphs，输入是tree,0.mdl和L.fst,输出是fits.JOB.gz，其是在训练过程中构建graph的过程；<br>3.接下来是一个对齐的操作，kaldi-trunk/source/bin/align-equal-compiled；<br>4.然后是基于GMM的声学模型进行最大似然估计得过程，脚本为/kaldi-trunk/src/gmmbin/gmm-est；<br>5.然后进行迭代循环中进行操作，如果本步骤到了对齐的步骤，则调用脚本kaldi-kaldi/src/gmmbin/gmm-align-compiled；<br>6.重新估计GMM，累计状态，用脚本/kaldi-trunk/src/gmmbin/gmm-acc-states-ali；调用新生成的参数(高斯数)重新估计GMM，调用脚本/kaldi-trunk/src/gmmbin/gmm-est；<br>7.对分散在不同处理器上的结果进行合并，生成.mdl结果，调用脚本gmm-acc-sum；<br>8.增加高斯数，如果没有超过设定的迭代次数，则跳转到步骤5重新进行训练<br>最后生成的.mdl即为声学模型文件<br>在离线识别阶段，即可以调用utils/mkgraph.sh；来对刚刚生成的声学文件进行构图<br>之后解码，得到离线测试的识别率。</p>
</blockquote>
<h4 id="3-Monophone-decoding-单音素解码"><a href="#3-Monophone-decoding-单音素解码" class="headerlink" title="3. (Monophone decoding) 单音素解码"></a>3. (Monophone decoding) 单音素解码</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">utils/mkgraph.sh data/lang_test exp/mono exp/mono/graph || exit 1;</span><br><span class="line">steps/decode.sh --cmd &quot;$decode_cmd&quot; --config conf/decode.config --nj 10 \</span><br><span class="line">  exp/mono/graph data/dev exp/mono/decode_dev</span><br><span class="line">steps/decode.sh --cmd &quot;$decode_cmd&quot; --config conf/decode.config --nj 10 \</span><br><span class="line">  exp/mono/graph data/test exp/mono/decode_test</span><br></pre></td></tr></table></figure>

<p><code>mkgraph.sh</code>将L_disambig.fst 和 G.fst 复合生成LG.fst。中间经历了我看不懂的处理。最终生成用于解码的 HCLG.fst。</p>
<h4 id="看不懂的部分"><a href="#看不懂的部分" class="headerlink" title="看不懂的部分"></a>看不懂的部分</h4><p>后面就已经看不懂了。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># Get alignments from monophone system.</span><br><span class="line">steps/align_si.sh --cmd &quot;$train_cmd&quot; --nj 10 \</span><br><span class="line">  data/train data/lang exp/mono exp/mono_ali || exit 1;</span><br><span class="line"></span><br><span class="line"># train tri1 [first triphone pass]</span><br><span class="line">steps/train_deltas.sh --cmd &quot;$train_cmd&quot; \</span><br><span class="line"> 2500 20000 data/train data/lang exp/mono_ali exp/tri1 || exit 1;</span><br><span class="line"></span><br><span class="line"># decode tri1</span><br><span class="line">utils/mkgraph.sh data/lang_test exp/tri1 exp/tri1/graph || exit 1;</span><br><span class="line">steps/decode.sh --cmd &quot;$decode_cmd&quot; --config conf/decode.config --nj 10 \</span><br><span class="line">  exp/tri1/graph data/dev exp/tri1/decode_dev</span><br><span class="line">steps/decode.sh --cmd &quot;$decode_cmd&quot; --config conf/decode.config --nj 10 \</span><br><span class="line">  exp/tri1/graph data/test exp/tri1/decode_test</span><br><span class="line"></span><br><span class="line"># align tri1</span><br><span class="line">steps/align_si.sh --cmd &quot;$train_cmd&quot; --nj 10 \</span><br><span class="line">  data/train data/lang exp/tri1 exp/tri1_ali || exit 1;</span><br><span class="line"></span><br><span class="line"># train tri2 [delta+delta-deltas]</span><br><span class="line">steps/train_deltas.sh --cmd &quot;$train_cmd&quot; \</span><br><span class="line"> 2500 20000 data/train data/lang exp/tri1_ali exp/tri2 || exit 1;</span><br><span class="line"></span><br><span class="line"># decode tri2</span><br><span class="line">utils/mkgraph.sh data/lang_test exp/tri2 exp/tri2/graph</span><br><span class="line">steps/decode.sh --cmd &quot;$decode_cmd&quot; --config conf/decode.config --nj 10 \</span><br><span class="line">  exp/tri2/graph data/dev exp/tri2/decode_dev</span><br><span class="line">steps/decode.sh --cmd &quot;$decode_cmd&quot; --config conf/decode.config --nj 10 \</span><br><span class="line">  exp/tri2/graph data/test exp/tri2/decode_test</span><br><span class="line"></span><br><span class="line"># train and decode tri2b [LDA+MLLT]</span><br><span class="line">steps/align_si.sh --cmd &quot;$train_cmd&quot; --nj 10 \</span><br><span class="line">  data/train data/lang exp/tri2 exp/tri2_ali || exit 1;</span><br><span class="line"></span><br><span class="line"># Train tri3a, which is LDA+MLLT,</span><br><span class="line">steps/train_lda_mllt.sh --cmd &quot;$train_cmd&quot; \</span><br><span class="line"> 2500 20000 data/train data/lang exp/tri2_ali exp/tri3a || exit 1;</span><br><span class="line"></span><br><span class="line">utils/mkgraph.sh data/lang_test exp/tri3a exp/tri3a/graph || exit 1;</span><br><span class="line">steps/decode.sh --cmd &quot;$decode_cmd&quot; --nj 10 --config conf/decode.config \</span><br><span class="line">  exp/tri3a/graph data/dev exp/tri3a/decode_dev</span><br><span class="line">steps/decode.sh --cmd &quot;$decode_cmd&quot; --nj 10 --config conf/decode.config \</span><br><span class="line">  exp/tri3a/graph data/test exp/tri3a/decode_test</span><br><span class="line"></span><br><span class="line"># From now, we start building a more serious system (with SAT), and we&apos;ll</span><br><span class="line"># do the alignment with fMLLR.</span><br><span class="line"></span><br><span class="line">steps/align_fmllr.sh --cmd &quot;$train_cmd&quot; --nj 10 \</span><br><span class="line">  data/train data/lang exp/tri3a exp/tri3a_ali || exit 1;</span><br><span class="line"></span><br><span class="line">steps/train_sat.sh --cmd &quot;$train_cmd&quot; \</span><br><span class="line">  2500 20000 data/train data/lang exp/tri3a_ali exp/tri4a || exit 1;</span><br><span class="line"></span><br><span class="line">utils/mkgraph.sh data/lang_test exp/tri4a exp/tri4a/graph</span><br><span class="line">steps/decode_fmllr.sh --cmd &quot;$decode_cmd&quot; --nj 10 --config conf/decode.config \</span><br><span class="line">  exp/tri4a/graph data/dev exp/tri4a/decode_dev</span><br><span class="line">steps/decode_fmllr.sh --cmd &quot;$decode_cmd&quot; --nj 10 --config conf/decode.config \</span><br><span class="line">  exp/tri4a/graph data/test exp/tri4a/decode_test</span><br><span class="line"></span><br><span class="line">steps/align_fmllr.sh  --cmd &quot;$train_cmd&quot; --nj 10 \</span><br><span class="line">  data/train data/lang exp/tri4a exp/tri4a_ali</span><br><span class="line"></span><br><span class="line"># Building a larger SAT system.</span><br><span class="line"></span><br><span class="line">steps/train_sat.sh --cmd &quot;$train_cmd&quot; \</span><br><span class="line">  3500 100000 data/train data/lang exp/tri4a_ali exp/tri5a || exit 1;</span><br><span class="line"></span><br><span class="line">utils/mkgraph.sh data/lang_test exp/tri5a exp/tri5a/graph || exit 1;</span><br><span class="line">steps/decode_fmllr.sh --cmd &quot;$decode_cmd&quot; --nj 10 --config conf/decode.config \</span><br><span class="line">   exp/tri5a/graph data/dev exp/tri5a/decode_dev || exit 1;</span><br><span class="line">steps/decode_fmllr.sh --cmd &quot;$decode_cmd&quot; --nj 10 --config conf/decode.config \</span><br><span class="line">   exp/tri5a/graph data/test exp/tri5a/decode_test || exit 1;</span><br><span class="line"></span><br><span class="line">steps/align_fmllr.sh --cmd &quot;$train_cmd&quot; --nj 10 \</span><br><span class="line">  data/train data/lang exp/tri5a exp/tri5a_ali || exit 1;</span><br><span class="line"></span><br><span class="line"># nnet3</span><br><span class="line">local/nnet3/run_tdnn.sh</span><br><span class="line"></span><br><span class="line"># chain</span><br><span class="line">local/chain/run_tdnn.sh</span><br></pre></td></tr></table></figure>

<h3 id="获取结果"><a href="#获取结果" class="headerlink" title="获取结果"></a>获取结果</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># getting results (see RESULTS file)</span><br><span class="line">for x in exp/*/decode_test; do [ -d $x ] &amp;&amp; grep WER $x/cer_* | utils/best_wer.sh; done 2&gt;/dev/null</span><br><span class="line">for x in exp/*/*/decode_test; do [ -d $x ] &amp;&amp; grep WER $x/cer_* | utils/best_wer.sh; done 2&gt;/dev/null</span><br><span class="line">exit 0;</span><br></pre></td></tr></table></figure>

<p>和上一篇文章一样的步骤。<br><a href="https://www.jianshu.com/p/09deba57f339" target="_blank" rel="noopener">Kaldi入门：yesno项目</a></p>
]]></content>
      <tags>
        <tag>Kaldi</tag>
        <tag>ASR</tag>
      </tags>
  </entry>
</search>
